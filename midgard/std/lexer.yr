mod std::lexer
    
import core::object, core::typeinfo, core::array;
import core::exception;
import std::tokenizer;
import std::collection::set;
import std::io, std::stream;

pub class @final SyntaxError over Exception {

    pub let msg : [c32];
    pub let line : u64;
    pub let col : u64;
    
    pub self (msg : [c32], line : u64, col : u64)
        with msg = msg, line = line, col = col
    {}

    impl Streamable {
        pub over toStream (self, dmut stream : &StringStream) {            
            stream:.write ("SyntaxError ("s8):.write (self.line):.write (","s8):.write (self.col):.write (") : "):.write (self.msg);
            if (self.trace.len != 0u64) {
                stream:.write (": "s8):.write (self.getStackTrace ());               
            }
        }
    }        
}

/**
 * This class use a tokenizer to split a string into tokens
 * Unlike a simple tokenizer, this class is able to skip undesirable tokens, such as white space or comments
 * It also follow the locations of the tokens inside the string, thus enabling error pointing 
 * @example: 
 * =============
 * let dmut lexer = Lexer::new ("test + foo * u", tokens-> ["+", "*"]);
 * loop {
 *    let (word, line, col) = lexer:.next ();
 *    println (word, " (", line, ", ", col, ")"); // test (1, 1), + (1, 6), foo (1, 8), * (1, 12), u (1, 14), (0,0)
 *    if line == 0 { 
 *        break {}  // eof
 *    } 
 * }
 * =============
 */
pub class if (is!T {U of c8} || is!T {U of c32}) @final Lexer {T} {

    let dmut _tzer : &Tokenizer!{T};

    let mut _content : [T];

    let dmut _comments = HashSet!([T])::new ();

    let dmut _skips = HashSet!([T])::new ();
    
    let mut _doSkip = true;

    let mut _doComments = true;
    
    let mut _line = 1u64;

    let mut _col = 1u64;

    /**
     * Create a new lexer, ready to split content
     * @params: 
     *    - content: the content to split
     *    - tokens: the list of tokens that split the string, (cf. Tokenizer)
     *    - comments: the list of tokens that start a comment line (by default ["#'])
     *    - skips: the list of tokens that will be omitted by the lexer when reading (by default [" ", "\n", "\t", "\r"])
     * @warning: if the skips and comments token are not in tokens, they are added, so they split the content 
     */
    pub self (content : [T], tokens: [[T]] = { cte if (is!T {U of c8}) { [" "s8] } else { [" "] } } , comments : [[T]] = { cte if (is!T {U of c8}) { ["#"s8] } else { ["#"] } }, skips: [[T]] = { cte if (is!T {U of c8}) { [" "s8, "\n"s8, "\t"s8, "\r"s8] } else { [" ", "\r", "\n", "\t"] } })
        with _tzer = Tokenizer::new (tokens-> tokens),
    _content = content
    {
        cte if (is!T {U of c8}) {
            self._tzer:.insert ("\n"s8); // We must have a return line for the lexer to work properly
        } else {
            self._tzer:.insert ("\n"); // We must have a return line for the lexer to work properly
        }
        
        for i in skips {
            self._skips:.insert (i);
            self._tzer:.insert (i);
        }

        for i in comments {
            self._comments:.insert (i);
            self._tzer:.insert (i);
        }
    }

    /**
     * @returns: the current content of the lexer
     */
    pub def getContent (self)-> [T] {
        self._content
    }

    /**
     * Change the current content of the lexer
     */
    pub def restoreContent (mut self, content : [T]) {
        self._content = content;
    }

    /**
     * Move the cursor of the lexer forward and return the word that has been read
     * @returns: 
     *    - ._0: the content of the word ("" if no word) 
     *    - ._1: the line of the beginning of the word (0 if no word)
     *    - ._2: the col of the beginning of the word (0 if no word)
     */
    pub def next (mut self) -> ([T], u64, u64) {
        loop {
            let wd = self._tzer.next (self._content);
            if (wd != 0u64) {
                {
                    let ret = self._content [0us..wd];
                    self._content = self._content [wd..$];
                    
                    let (line, col) = (self._line, self._col);                        
                    let pos = self:.countNbLine (ret, self._line, self._col);
                    self._line = pos._0;
                    self._col = pos._1;
                    
                    if self._doComments && ret in self._comments {
                        self._content = self:.skipComments (self._content);
                        self._line += 1u64;
                    } else if !self._doSkip || ret !in self._skips {
                        return (ret, line, col);
                    } 
                } catch {
                    _ : &OutOfArray => { } // Impossible 
                }
            } else {
                cte if (is!T {U of c8}) {
                    break (""s8, 0u64, 0u64);
                } else {
                    break ("", 0u64, 0u64);
                }
            }
        }
    }

    /**
     * Move the cursor of the lexer forward and return the next char 
     * @info: do not consider tokens, comments and skips
     * @returns: 
     *    - ._0: the content of the word ("" if no word) 
     *    - ._1: the line of the beginning of the word (0 if no word)
     *    - ._2: the col of the beginning of the word (0 if no word)
     */
    pub def nextChar (mut self)-> ([T], u64, u64) {
        let wd = 1u64;
        if (wd != 0u64) {
            let ret = self._content [0u64..wd];
            self._content = self._content [wd..cast!u64 ($)];
            
            let (line, col) = (self._line, self._col);                        
            let pos = self:.countNbLine (ret, self._line, self._col);
            self._line = pos._0;
            self._col = pos._1;
            
            return (ret, line, col);             
        } catch {
            _ : &OutOfArray => { } // Impossible 
        }

        cte if (is!T {U of c8}) {
            (""s8, 0u64, 0u64)
        } else {
            ("", 0u64, 0u64)
        }
    }

    /**
     * Read the next word inside the content of the lexer, but does not advance the cursor of the lexer
     * This function is used to the next, and decide afterward to treat it or not
     * @returns: 
     *    - ._0: the content of the word ("" if no word) 
     *    - ._1: the line of the beginning of the word (0 if no word)
     *    - ._2: the col of the beginning of the word (0 if no word)
     */
    pub def nextNoConsume (mut self) -> ([T], u64, u64) {
        let mut aux_content = self._content;
        let mut pos: (mut u64, mut u64) = (self._line, self._col);
        
        loop {
            let wd = self._tzer.next (aux_content);
            if (wd != 0u64) {
                {
                    let ret = aux_content [0us..wd];
                    aux_content = aux_content [wd..$];
                    
                    let (line, col) = pos;
                    pos = self:.countNbLine (ret, pos._0, pos._1);
                    
                    if self._doComments && ret in self._comments {
                        aux_content = self:.skipComments (aux_content);
                        pos._0 += 1u64;
                        
                    } else if !self._doSkip || ret !in self._skips {
                        return (ret, line, col);
                    } 
                } catch {
                    _ : &OutOfArray => { } // Impossible 
                }
            } else {
                cte if (is!T {U of c8}) {
                    break (""s8, 0u64, 0u64);
                } else {
                    break ("", 0u64, 0u64);
                }
            }
        }
    }

    /**
     * Tell to the lexer if it must skip the 'skips' or not
     * @info: 
     *   - by default the lexer skips them
     *   - This function is used to disable token skipping when reading string content for example
     */
    pub def doSkip (mut self, d : bool) -> void {
        self._doSkip = d;
    }

    /**
     * Tell to the lexer if it must skip the 'comments' or not
     * @info: 
     *   - by default the lexer skips them
     *   - This function is used to disable token skipping when reading string content for example
     */
    pub def doComments (mut self, d : bool) -> void {
        self._doComments = d;
    }

    /**
     * Move the cursor of buf to the next line, in order to skip the comments
     * @params: 
     *   - buf: the content 
     * @returns: a slice of content, where the first line has been removed
     */
    prv def skipComments (self, buf : [T])-> mut [T] {
        let mut content = buf;
        {
            loop {
                let wd = self._tzer.next (content);
                if (wd == 0us) break {}
                let ret = content [0us..wd];
                content = content [wd.. $];                

                cte if (is!T {U of c8}) {
                    if (ret == "\n"s8) break {}
                } else {
                    if (ret == "\n") break {}
                }
            }
        } catch {
            _ : &OutOfArray => { } // impossible
        }
        
        return content;
    }

    /**
     * Increment the number of line if the content of the word is a line return
     * @returns: 
     *   - ._0: the new line number
     *   - ._1: the new column number
     */
    prv def countNbLine (self, word : [T], line : u64, col : u64) -> (u64, u64) {
        cte if (is!T{U of c8}) {
            if (word == "\n"s8) {
                (line + 1u64, 1u64)
            } else {
                (line, col + word.len)
            }
        } else {
            if (word == "\n") {
                (line + 1u64, 1u64)
            } else {
                (line, col + word.len)
            }
        }
    }

    /**
     * Clear the lexer, and return the rest of the text that was not read yet
     * @example: 
     * ======================
     * let dmut lex = Lexer::new ("text to read");
     * 
     * assert (lex:.next ()._0 == "next");
     * assert (lex:.clear () == " to read");
     * assert (lex:.next ()._0 == "")
     * ======================
     */
    pub def clear (mut self)-> [T] {
        let ret = self._content;
        self._content = [];
        ret
    }
    
}



